<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>Shinwoo Park | CV</title>
  <link rel="stylesheet" href="assets/css/style.css">
  <link href="https://fonts.googleapis.com/css2?family=Inter&display=swap" rel="stylesheet">
  <style>
    body {
      line-height: 1.65;
    }

    .main {
      padding: 2.5rem 3rem;
      max-width: 960px;
      margin: 0 auto;
    }

    .section {
      margin-bottom: 3rem;
    }

    .section h2 {
      font-size: 1.6rem;
      border-bottom: 2px solid #ccc;
      padding-bottom: 0.2rem;
      margin-bottom: 1.2rem;
      color: #0d6efd;
    }

    .section h3 {
      font-size: 1.2rem;
      margin-top: 2rem;
      margin-bottom: 0.5rem;
      color: #222;
    }

    .section p,
    .section li {
      font-size: 0.96rem;
      color: #333;
    }

    .section ul {
      padding-left: 1.2em;
      margin-top: 0.5em;
    }

    .section li {
      margin-bottom: 0.8em;
    }

    .label {
      font-weight: 600;
      color: #444;
    }

    .sidebar h1 {
      font-size: 1.5rem;
    }

    @media screen and (max-width: 768px) {
      .main {
        padding: 1.5rem;
        max-width: 100%;
      }
    }
  </style>
</head>

<body>
  <div class="sidebar">
    <img src="assets/img/profile.jpg" alt="Profile">
    <h1>Shinwoo Park</h1>
    <p>Ph.D. Candidate in Artificial Intelligence<br>Yonsei University</p>
    <nav>
      <a href="index.html">Home</a>
      <a href="publications.html">Publications</a>
      <a href="cv.html">CV</a>
      <a href="contact.html">Contact</a>
    </nav>
  </div>

  <div class="main">
    <section class="section">
      <h2>CV</h2>

      <p><span class="label">Name:</span> Shinwoo Park</p>
      <p><span class="label">Position:</span> Ph.D. Candidate in Artificial Intelligence</p>
      <p><span class="label">Affiliation:</span> Yonsei University, Seoul, South Korea</p>
      <p><span class="label">Expected Graduation:</span> February 2026</p>

      <h3>Research Interests</h3>
      <p>
        My research focuses on ensuring the <strong>safety, transparency, and accountability</strong> of large language models (LLMs) 
        through <strong>detection</strong> and <strong>watermarking</strong> techniques. 
        I develop multi-modal and multi-lingual systems that identify or trace LLM-generated content 
        across <strong>natural language and source code</strong> domains.
      </p>
      <p>
        Specifically, I explore two complementary directions:
        (1) <strong>linguistic and stylistic feature–based detection</strong>, which analyzes morphological, syntactic, and stylistic patterns to distinguish human- and LLM-generated text or code; and 
        (2) <strong>LLM watermarking</strong>, which embeds imperceptible yet verifiable statistical or structural signals into generated outputs.
      </p>
      <p>
        My recent works include <em>KatFishNet</em>, the first linguistic feature–based detector for Korean text; 
        <em>LPcodedec</em>, a coding-style-driven detector for paraphrased code; 
        <em>STELA</em>, a syntactic-predictability watermark enabling model-free detection; 
        and <em>WaterMod</em>, a probability-balanced modular watermarking framework supporting multi-bit payloads.
      </p>
      <p>
        Broadly, my goal is to build <strong>trustworthy generative systems</strong> that are interpretable, 
        regulation-compliant, and resistant to misuse.
      </p>
      
      <h3>Research Summary</h3>
      <p>
        My research aims to promote <strong>responsible and verifiable AI generation</strong> by developing reliable methods for detecting and attributing LLM-generated text and code.
        I pursue two main directions that mutually reinforce each other:
      </p>
      <ul>
        <li>
          <strong>Linguistic/Stylistic Feature-based Detection:</strong> 
          Models such as <em>KatFishNet</em> and <em>LPcodedec</em> analyze linguistic or coding-style cues—word spacing, part-of-speech diversity, punctuation patterns, naming and indentation consistency—to capture distributional differences between human and LLM authors.
        </li>
        <li>
          <strong>LLM Watermarking:</strong> 
          Frameworks such as <em>STELA</em> and <em>WaterMod</em> embed imperceptible signals during generation using linguistically or probabilistically adaptive mechanisms,
          enabling <em>publicly verifiable</em> and <em>multi-bit</em> attribution without harming fluency.
        </li>
      </ul>
      <p>
        These systems demonstrate strong <strong>multilingual</strong> (English, Korean) and <strong>multimodal</strong> (text + code) generalization,
        advancing interpretable and regulation-aligned AI provenance research.
      </p>
      
      <h3>Research Statement</h3>
      <p>
        My long-term research vision is to establish a <strong>unified framework for provenance-aware and interpretable AI</strong> 
        that spans both language and programming modalities.
        To achieve this, I combine linguistic insight, statistical modeling, and watermark design to construct transparent interfaces 
        between human communication and generative models.
      </p>
      
      <p>
        <span class="label">Linguistic / Stylistic Feature-based Detection:</span><br>
        My work on <em>KatFishNet</em> introduces the first benchmark and detector for LLM-generated Korean text, 
        leveraging word-spacing irregularities, POS n-gram diversity, and comma usage to expose cross-morphological differences between human and machine writing.
        Extending this idea to source code, <em>LPcodedec</em> identifies LLM-paraphrased code by quantifying coding-style features such as naming consistency, indentation regularity, and comment ratio.
      </p>
      
      <p>
        <span class="label">LLM Watermarking:</span><br>
        My research advances from distribution-based watermarking to <strong>linguistically adaptive</strong> and <strong>probability-balanced</strong> methods.
        <em>STELA</em> modulates watermark strength according to syntactic predictability modeled by POS n-gram entropy, enabling <em>model-free</em> public detection.
        <em>WaterMod</em> generalizes this concept through modular token-rank partitioning that guarantees at least one high-probability token per class,
        supporting <em>zero-bit</em> and <em>multi-bit</em> watermarking with minimal quality loss.
      </p>
      
      <p>
        Together, these studies form a coherent agenda for <strong>trustworthy and interpretable generative AI</strong>, 
        bridging linguistic analysis and information-theoretic watermark design to meet emerging transparency and safety requirements.
      </p>
      
      <h3>Publications</h3>

      <br>

      <p>† <strong>First author</strong> &nbsp;&nbsp; †* <strong>Co-first author</strong> (marked with *)</p>

      <h3>To Appear / Published</h3>

      <br>

      <div class="paper">
        <p><strong><i>DITTO: A Spoofing Attack Framework on Watermarked LLMs via Knowledge Distillation</i></strong></p>
        <p class="authors">Hyeseon Ahn, <strong>Shinwoo Park</strong>, Suyeon Woo, Yo-Sub Han</p>
        <p class="venue">EACL, Main Conference, to appear, 2026.</p>
      </div>
      
      <br>
      
      <div class="paper">
        <p><strong><i>Marking Code Without Breaking It: Code Watermarking for Detecting LLM-Generated Code</i></strong></p>
        <p class="authors">Jungin Kim †*, <strong>Shinwoo Park †*</strong>, Yo-Sub Han</p>
        <p class="venue">EACL, Findings, to appear, 2026.</p>
        <p><small>* Equal contribution</small></p>
      </div>

      <br>

      <div class="paper">
        <p><strong><i>WaterMod: Modular Token-Rank Partitioning for Probability-Balanced LLM Watermarking</i></strong></p>
        <p class="authors"><strong>Shinwoo Park</strong> †, Hyejin Park, Hyeseon Ahn, Yo-Sub Han</p>
        <p class="venue">AAAI, to appear (Oral), 2026.</p>
      </div>

      <br>

      <div class="paper">
        <p><strong><i>EnCur: Curriculum-Based In-Context Learning with Structural Encoding for Code Time Complexity Prediction</i></strong></p>
        <p class="authors">Joonghyuk Hahn, Aditi, SeungYeop Baik, <strong>Shinwoo Park</strong>, Sang-Ki Ko, Yo-Sub Han</p>
        <p class="venue">Expert Systems with Applications, Vol. 296, 129094, January 2026.</p>
      </div>

      <br>

      <div class="paper">
          <p><strong><i>Detecting Code Paraphrased by Large Language Models using Coding Style Features</i></strong></p>
          <p class="authors"><strong>Shinwoo Park</strong> †, Hyundong Jin, Jeong-Won Cha, Yo-Sub Han</p>
          <p class="venue">Engineering Applications of Artificial Intelligence, Vol. 162, December 2025.</p>
        </div>

      <br>

      <div class="paper">
          <p><strong><i>Mondrian: A Framework for Logical Abstract (Re)Structuring</i></strong></p>
          <p class="authors">Elizabeth Grace Orwig, <strong>Shinwoo Park</strong>, Hyundong Jin, Yo-Sub Han</p>
          <p class="venue">EMNLP 2025 (Main Conference), pp. 33663--33678.</p>
      </div>

      <br>

      <div class="paper">
        <p><strong><i>TrapDoc: Deceiving LLM Users by Injecting Imperceptible Phantom Tokens into Documents</i></strong></p>
        <p class="authors">Hyundong Jin, Sicheol Sung, <strong>Shinwoo Park</strong>, SeungYeop Baik, Yo-Sub Han</p>
        <p class="venue">Findings of EMNLP 2025, pp. 18881--18897.</p>
      </div>

      <br>

      <div class="paper">
          <p><strong><i>Advanced Code Time Complexity Prediction Approach Using Contrastive Learning</i></strong></p>
          <p class="authors"><strong>Shinwoo Park</strong> †, Joonghyuk Hahn, Elizabeth Orwig, Sang-Ki Ko, Yo-Sub Han</p>
          <p class="venue">Engineering Applications of Artificial Intelligence, Vol. 151, July 2025.</p>
      </div>

      <br>

      <div class="paper">
          <p><strong><i>KatFishNet: Detecting LLM-Generated Korean Text through Linguistic Feature Analysis</i></strong></p>
          <p class="authors"><strong>Shinwoo Park</strong> †, Shubin Kim, Do-Kyung Kim, Yo-Sub Han</p>
          <p class="venue">ACL 2025 (Main Conference), pp. 21189–21222.</p>
      </div>

      <br>

      <div class="paper">
          <p><strong><i>ConPrompt: Pre-training a Language Model with Machine-Generated Data for Implicit Hate Speech Detection</i></strong></p>
          <p class="authors">Youngwook Kim, <strong>Shinwoo Park</strong>, Youngsoo Namgoong, Yo-Sub Han</p>
          <p class="venue">Findings of EMNLP 2023, pp. 10964–10980.</p>
      </div>

      <br>

      <div class="paper">
          <p><strong><i>Contrastive Learning with Keyword-based Data Augmentation for Code Search and Code Question Answering</i></strong></p>
          <p class="authors"><strong>Shinwoo Park</strong> †, Youngwook Kim, Yo-Sub Han</p>
          <p class="venue">EACL 2023 (Main Conference), pp. 3609–3619.</p>
      </div>

      <br>

      <div class="paper">
          <p><strong><i>Generalizable Implicit Hate Speech Detection using Contrastive Learning</i></strong></p>
          <p class="authors">Youngwook Kim, <strong>Shinwoo Park</strong>, Yo-Sub Han</p>
          <p class="venue">COLING 2022, pp. 6667–6679.</p>
      </div>

      <h3>Under Review</h3>

      <br>

      <div class="paper">
        <p><strong><i>A Linguistics-Aware LLM Watermarking via Syntactic Predictability</i></strong></p>
        <p class="authors"><strong>Shinwoo Park</strong> †, Hyejin Park, Hyeseon Ahn, Yo-Sub Han</p>
      </div>

      <br>

      <div class="paper">
          <p><strong><i>Select then MixUp: Improving Out-of-Distribution Natural Language Code Search</i></strong></p>
          <p class="authors"><strong>Shinwoo Park</strong> † and Yo-Sub Han</p>
      </div>

      <h3>Projects</h3>
      <ul>
        <li><span class="label">AI for Issue-Fact Mapping (2021–2022):</span><br>
          Knowledge graph entity retrieval from unstructured text using topic modeling.</li>
        <li><span class="label">Medical Text Mining (2022–2025):</span><br>
          Clinical insight extraction from medical records using topic modeling.</li>
        <li><span class="label">Human-AI Programming Lab (2023–2025):</span><br>
          Code search, QA, and time complexity prediction for collaborative coding systems.</li>
        <li><span class="label">Research on Effective Watermarking Techniques for AI-generated Codes (2025--):</span><br>
          Conducted research on a watermarking technique that intervenes in the code generation process of LLMs, embedding watermarks while preserving the code’s quality and functionality.</li>
      </ul>

      <h3>Professional Services</h3>
      <ul>
        <li><span class="label">Reviewer, ACL Rolling Review (2023--)</span><br></li>
      </ul>

      <h3>Skills</h3>
      <ul>
        <li><span class="label">Programming:</span> Python, Java, C, C++, Bash</li>
        <li><span class="label">ML Frameworks:</span> PyTorch, scikit-learn, Hugging Face Transformers</li>
        <li><span class="label">NLP:</span> SpaCy, NLTK, KoNLPy, KiwiPiePy</li>
        <li><span class="label">LLM APIs:</span> OpenAI API, Gemini API, Ollama</li>
        <li><span class="label">Data Analysis:</span> Pandas, NumPy, SciPy</li>
        <li><span class="label">Visualization:</span> Matplotlib, Seaborn</li>
        <li><span class="label">Version Control:</span> Git</li>
        <li><span class="label">Writing:</span> LaTeX</li>
        <li><span class="label">Languages:</span> Korean (native), English (fluent)</li>
      </ul>
    </section>
  </div>
</body>
</html>
