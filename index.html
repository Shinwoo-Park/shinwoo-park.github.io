<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>Shinwoo Park | Home</title>
  <link rel="stylesheet" href="assets/css/style.css">
  <link href="https://fonts.googleapis.com/css2?family=Inter&display=swap" rel="stylesheet">
  <style>
    body {
      line-height: 1.65;
    }

    .main {
      padding: 2.5rem 3rem;
      max-width: 960px;
      margin: 0 auto;
    }

    .section {
      margin-bottom: 3rem;
    }

    .section h2 {
      font-size: 1.6rem;
      border-bottom: 2px solid #ccc;
      padding-bottom: 0.2rem;
      margin-bottom: 1.2rem;
      color: #0d6efd;
    }

    .section h3 {
      font-size: 1.2rem;
      margin-top: 2rem;
      margin-bottom: 0.5rem;
      color: #222;
    }

    .section p,
    .section li {
      font-size: 0.96rem;
      color: #333;
    }

    .section ul {
      padding-left: 1.2em;
      margin-top: 0.5em;
    }

    .section li {
      margin-bottom: 0.8em;
    }

    .label {
      font-weight: 600;
      color: #444;
    }

    .sidebar h1 {
      font-size: 1.5rem;
    }

    @media screen and (max-width: 768px) {
      .main {
        padding: 1.5rem;
        max-width: 100%;
      }
    }
  </style>
</head>

<body>
  <div class="sidebar">
    <img src="assets/img/profile.jpg" alt="Profile">
    <h1>Shinwoo Park</h1>
    <p>Ph.D. Candidate in Artificial Intelligence<br>Yonsei University</p>
    <nav>
      <a href="index.html">Home</a>
      <a href="publications.html">Publications</a>
      <a href="cv.html">CV</a>
      <a href="contact.html">Contact</a>
    </nav>
  </div>
    <div class="main">
        <section class="section">
            <h2>About Me</h2>
            <p>
              I am a <strong>Ph.D. candidate in Artificial Intelligence</strong> at the 
              <em>Theory of Computation (ToC) Lab</em>, <strong>Yonsei University</strong>, 
              advised by <strong>Prof. Yo-Sub Han</strong>.
            </p>
            <p>
              My research aims to enhance the <strong>safety, transparency, and interpretability</strong> 
              of large language models (LLMs) through <strong>detection</strong> and 
              <strong>attribution</strong> techniques. Specifically, I investigate two complementary directions:
            </p>
            <ul>
              <li>
                <strong>Linguistic and stylistic featureâ€“based detection</strong>, which distinguishes 
                human- and LLM-generated text or code by analyzing subtle differences in writing patterns; and
              </li>
              <li>
                <strong>LLM watermarking</strong>, which embeds imperceptible signals into generated outputs 
                to enable reliable provenance tracing.
              </li>
            </ul>
            <p>
              I have developed <strong>multi-modal</strong> and <strong>multi-lingual</strong> systems for detecting 
              and watermarking AI-generated content across <strong>natural language</strong> and 
              <strong>source code</strong> in English, Korean, Python, C, C++, and Java.
            </p>
            <p>
              More broadly, I am deeply interested in <strong>AI safety</strong>, 
              <strong>responsible AI</strong>, and <strong>interpretable model design</strong> 
              for building trustworthy and accountable generative systems.
            </p>
        </section>
        <section class="section">
            <h2>Research Interests</h2>
            <ul>
              <li>Detection of LLM-Generated Text/Code using Linguistic/Stylistic Features</li>
              <li>LLM Watermarking for LLM-Generated Text/Code Attribution and Provenance</li>
              <li>Human-Centric AI Safety</li>
              <li>Responsible and Interpretable AI</li>
              <li>Linguistics + AI (Especially, Korean)</li>
            </ul>
        </section>
        <section class="section">
            <h2>Recent News</h2>
            <ul>
                <li>[Jan 2026] Two LLM watermarking papers have been accepted to <i>EACL 2026</i> (<i>Main</i> and <i>Findings</i>).</li>
                <li>[Nov 2025] My first LLM watermarking paper (<a href="https://arxiv.org/pdf/2511.07863">WaterMod</a>) has been accepted to <i>AAAI 2026 (Oral)</i>!</li>
                <li>[Oct 2025] New preprint STELA:<a href="https://arxiv.org/pdf/2510.13829">"A Linguistics-Aware LLM Watermarking via Syntactic Predictability"</a> is now available on arXiv.</li>
                <li>[Sep 2025] Paper accepted to <i>Engineering Applications of Artificial Intelligence</i>. <a href="https://arxiv.org/pdf/2502.17749">Detector for LLM-paraphrased code.</a></li>
                <li>[Aug 2025] Two papers accepted to <i>EMNLP 2025</i> (<i>Main</i> and <i>Findings</i>).</li>
                <li>[Aug 2025] Presented <i><a href="https://aclanthology.org/2025.acl-long.1030.pdf">KatFishNet (LLM-generated Korean text detector)</a></i> at <i>ACL 2025 (Main)</i> in Vienna, Austria.</li>
                <li>[July 2025] Paper accepted to <i>Expert Systems with Applications</i>.</li>
                <li>[June 2025] Paper accepted to <i>ACL 2025 (Main)</i>. Detector for LLM-generated Korean text.</li>
                <li>[March 2025] Paper accepted to <i>Engineering Applications of Artificial Intelligence</i>.</li>
            </ul>
        </section>
    </div>
</body>
</html>